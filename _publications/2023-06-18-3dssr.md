---
title: "3DSSR: 3D Subscene Retrieval"
collection: publications
permalink: /publication/2023-06-18-3dssr
date: 2023-06-18
citation: '<b>Reza Asad </b>, Manolis Savva . <i>IEEE Computer Vision and Pattern Recognition</i>. <b> CVPR 2023 Workshop on Structural and Compositional Learning on 3D Data</b>.'
---
[[PDF]](https://openaccess.thecvf.com/content/CVPR2023W/StruCo3D/papers/Asad_3DSSR_3D_Subscene_Retrieval_CVPRW_2023_paper.pdf)[[Video]](https://www.youtube.com/watch?v=jMZFzJnu6Sk)[[Code]](https://github.com/reza-asad/3DSSR)

## Abstract
We present the task of 3D subscene retrieval (3DSSR). In this task a user specifies a query object and a set of context objects in a 3D scene. 
Then, a system retrieves and ranks subscenes from a database of 3D scenes that best correspond to the configuration defined by the query. 
This formulation generalizes prior work on context-based 3D object retrieval and 3D scene retrieval. To tackle this task we present 
PointCrop: a self-supervised point cloud encoder training scheme that enables retrieval of geometrically similar subscenes without relying 
on object category supervision. We evaluate PointCrop against alternative methods and baselines through a suite of evaluation metrics that measure 
the degree of subscene correspondence. Our experiments show that PointCrop training outperforms supervised and prior self-supervised training paradigms
by 4.33% and 9.11% in mAP respectively. 
